# -*- coding: utf-8 -*-
"""Stripe task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jh2HtGdB7YL2lW-jVn49tdKW0BzQyNuQ
"""

# importing relevant libraries
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
import numpy as np

"""The files have been stored in a google drive. The step below is directly reading the files from the drive given the path."""

# reading all the files from google drive
df_payout = pd.read_csv('/content/drive/MyDrive/Stripe dataset/payouts (1).csv')
df_countries = pd.read_csv('/content/drive/MyDrive/Stripe dataset/countries - countries.csv.csv')
df_industries = pd.read_csv('/content/drive/MyDrive/Stripe dataset/industries - industries.csv.csv')

"""## Exploratory Data Analysis on each of the three files.
Checking for null and duplicated values.

Payout file does not have null values.
"""

# EDA on payouts csv file
df_payout.info()
print(f"\n {df_payout.head()}")
print(f"\nThe total no. of missing values in the dataframe are shown here:\n {df_payout.isna().sum()}")

"""However, the date column is in atime series format. We only need the date to solve for the first question.
So, from the date column, we extract only the date part, transform it and store it back to the same column.
"""

#Transforming the date column for better readability
df_payout['date'] = pd.to_datetime(df_payout['date'])
df_payout['date'] = df_payout['date'].dt.date

"""# Question 1:

# Rationale:
To estimate the average payout to be made to each country on 1st Jan 2019, we will use predictive analytics,i.e. we will use historical data(data from 2018) to see the trend and estimate the behaviour on 1st Jan.

# Approach:
First we calcuate to see which day of the week is the payout to be determined for. In our case, it falls on a tuesday. Now, using data from 2018, we will analyze payouts made on each tuesdays of the year(present in our data), and then average it out to estimate an amount for the 1st.

The amount column has numeric values expressed in cents. For businesses, it is better to provide estimates in thousand denominations. To achieve this, we divide each amount values by 1000.

Further, based on the date extracted we determine which day of the week was the payout made in 2018. This will help us give a better estimate for the payout to be made on 1 jan 2019.
"""

# Converting the amount from cents to thousands
df_payout['amount(1000$)'] = df_payout['amount'].apply(lambda x: x / 100000)

# Extracting the date only from the time series column and then adding a new column 'weekday'.
# Based on the step from above, determining the day of the week
df_payout['weekday'] = pd.to_datetime(df_payout['date'])
df_payout['weekday'] = df_payout['weekday'].dt.dayofweek

"""Countries file has a few null values."""

# EDA on countries csv file
df_countries.info()
print(f"\n {df_countries.head()}")
print(f"\nThe total no. of missing values in the dataframe are shown here:\n {df_countries.isna().sum()}")
print(f"\nThe total no. of duplicated entries in the dataframe are shown here:\n {df_countries.duplicated().sum()}")

"""Industries file has one null entry."""

# EDA on industries csv file
df_industries.info()
print(f"\n {df_industries.head()}")
print(f"\nThe total % missing values in the dataframe are shown here:\n {df_industries.isna().sum()}")
na_rows = df_industries[df_industries.isna().any(axis=1)]
print(na_rows)
print(f"\nThe total no. of duplicated entries in the dataframe are shown here:\n {df_industries.duplicated().sum()}")

"""Now that we have perfomed preliminary EDA on all files, its time to answer join the payout file and the countries file.
We use a left join and merge the data to a new df and drop the redundant 'merchant_id' column. The missing values from countries file have been grouped in a new category named 'unknown'. The missing values account for a very low share as compared to the dataset so dropping the missing data could also be an alternative.
"""

# Merge the dataframes based on recipient_id and merchant_id
df_payout_country_merged = pd.merge(df_payout, df_countries, left_on='recipient_id', right_on='merchant_id', how='left')
df_payout_country_merged.drop(columns=['merchant_id'], inplace=True)
print(f"\nThe total no. of missing values in the dataframe are shown here:\n {df_payout_country_merged.isna().sum()}")
# Replacing NaN values with Unknown to create a new category
df_payout_country_merged['country'].fillna('Unknown', inplace=True)

"""Now we created a new df with only the columns that we need for the final estimation"""

# Creating a new df with only relevant columns
df_payout_country_merged_1 = df_payout_country_merged[['recipient_id','amount(1000$)','weekday','country']]
df_payout_country_merged_1

# Grouping the new df by weekday and country to estimate the amount
df_payout_country_merged_1 = df_payout_country_merged_1.groupby(['weekday', 'country'], as_index=False).sum()
df_payout_country_merged_1

df_payout_country_merged_wk = df_payout_country_merged_1.groupby(['weekday'], as_index=False).sum()
df_payout_country_merged_wk

# Create a colormap
from matplotlib.cm import Blues
from matplotlib.colors import Normalize
import matplotlib.pyplot as plt

# Create a colormap
cmap = Blues
norm = Normalize(vmin=min(df_payout_country_merged_wk['amount(1000$)']), vmax=max(df_payout_country_merged_wk['amount(1000$)']))  # Normalize the data

plt.figure(figsize=(10, 6))
plt.gca().set_facecolor('beige')  # Set the background color of the plot area
bars = plt.bar(df_payout_country_merged_wk['weekday'], df_payout_country_merged_wk['amount(1000$)'] / 1000, color=cmap(norm(df_payout_country_merged_wk['amount(1000$)'])))  # Use the colormap for coloring the bars
plt.xlabel('Weekday')
plt.ylabel('Amount (Millions of $)')
plt.title('Total Payout Amount in 2018 over each day of the week')

# Change the x-axis labels
weekday_labels = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
plt.xticks(df_payout_country_merged_wk['weekday'], weekday_labels)  # Set custom x-axis tick labels

# Create a ScalarMappable object for the colorbar
sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
sm.set_array([])  # Dummy array required for the colorbar
plt.colorbar(sm, label='Amount (1000$)')  # Add a colorbar for reference

# Add value labels over each bar
for bar, amount in zip(bars, df_payout_country_merged_wk['amount(1000$)']):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.1, f'{amount / 1000:.2f}M', ha='center', va='bottom')

plt.tight_layout()
plt.show()

"""Filtering the data where weekday == 1,i.e. where the payout was made on a tuesday."""

# Calculating the payout on tuesdays of 2018 by country
df_payout_country_merged_1 = df_payout_country_merged_1[df_payout_country_merged_1['weekday']== 1]
df_payout_country_merged_1

# Dividing the amount from above by 52 to get an estimate of payouts of tuesdays
df_payout_country_merged_1['estimated_amount_1jan(1000$)'] = df_payout_country_merged_1['amount(1000$)'].div(52)
df_payout_country_merged_1

# Plotting the vestimated amount vs country. Taking log of y-axis to normalize the data for better visualization
plt.figure(figsize=(12, 6))
bars = plt.bar(df_payout_country_merged_1['country'], df_payout_country_merged_1['estimated_amount_1jan(1000$)'], color='skyblue')
plt.xlabel('Country')
plt.ylabel('Estimated Payout Amount (1000$)')
plt.title('Estimated Payout Amount by Country in 2019')
plt.xticks(rotation=45, ha='right')
plt.yscale('log')  # Set y-axis to logarithmic scale

# Inserting values on each bar
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')

plt.tight_layout()
plt.show()

"""# Question 2:

Let's first look at how many industries are there in the file.
"""

df_industries['industry'].value_counts()

"""In the list, we see there are multiple groups of industries. There is one under "hotel" group. For better results, I grouped travel and hospitality and hotels into one group."""

df_industries['industry'] = df_industries['industry'].str.replace('Travel & Hospitality','hotels, restaurants & leisure' )

"""Using a left join, we merge both files,i.e. payouts and industries. We will not require dates and count columns, so we drop them."""

#create another df and delete some columns
df_payouts_industries_merged = pd.merge(df_payout, df_industries, how='left', left_on='platform_id', right_on='merchant_id')
df_payouts_industries_merged = df_payouts_industries_merged.drop(['date','recipient_id','count'], axis = 1)
df_payouts_industries_merged

#grouping the df by industry and counting the unique platforms for each industry
df_platforms_industries_sum = df_payouts_industries_merged.drop(['platform_id','weekday','merchant_id'], axis = 1)
df_platforms_industries_sum = df_platforms_industries_sum.groupby(('industry'), as_index=False).sum()
df_platforms_industries_sum

# Plotting the pie chart
plt.figure(figsize=(20, 20))
# Define custom colors
colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue', 'lightgreen', 'pink', 'cyan',
          'orange', 'lightblue', 'lightyellow', 'lightgrey', 'lavender', 'lightpink', 'lightseagreen',
          'lightsalmon', 'lightsteelblue']
plt.pie(df_platforms_industries_sum['amount(1000$)'], labels=df_platforms_industries_sum['industry'], autopct='%1.1f%%', startangle=140, colors=colors)
plt.title('Amount (1000$) by Industry')
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

"""Now we see the unique industries with the count of unique platforms. This will help us analyze and estimate the payout volume better."""

#grouping the df by industry and counting the unique platforms for each industry
df_platforms_industries = df_payouts_industries_merged.groupby('industry')['platform_id'].nunique()
df_platforms_industries

#remove unneccessary columns
df_payouts_industries_merged.info()
df_payouts_industries_merged = df_payouts_industries_merged.drop(['platform_id','merchant_id'], axis = 1)

#Grouping the df based on only the 3 industries
df_payouts_industries_merged_1 = df_payouts_industries_merged.groupby(['industry','weekday'], as_index=False).sum()
industries = ['Education','Food & Beverage', 'hotels, restaurants & leisure']
df_payouts_industries_merged_2 = df_payouts_industries_merged_1[df_payouts_industries_merged_1.industry.isin(industries)]

df_payouts_industries_merged_2

from matplotlib.colors import LinearSegmentedColormap
# List of unique industry categories
categories = df_payouts_industries_merged_2['industry'].unique()

# Define the gradient color map
colors = ['mediumpurple', 'skyblue']  # Start and end colors for the gradient
cmap = LinearSegmentedColormap.from_list('mycmap', colors)

# Plotting each category in separate graphs
for category in categories:
    plt.figure(figsize=(10, 6))

    # Filter data for the current category
    df_category = df_payouts_industries_merged_2[df_payouts_industries_merged_2['industry'] == category]

    # Calculate the color gradient for each bar
    gradient_colors = np.linspace(0, 1, len(df_category))

    # Change the x-axis labels
    weekday_labels = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    plt.xticks(df_category['weekday'], weekday_labels)  # Set custom x-axis tick labels

    bars = plt.bar(df_category['weekday'], df_category['amount(1000$)'], color=cmap(gradient_colors))
    plt.xlabel('Weekday')
    plt.ylabel('Amount (1000$)')
    plt.title(f'Avg Payout Amount for {category} Industry by Weekday')
    plt.xticks(df_category['weekday'])

    # Add value labels over each bar
    for bar, amount in zip(bars, df_category['amount(1000$)']):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 100, f'{amount:.2f}', ha='center', va='bottom')

    plt.tight_layout()
    plt.show()

"""There is going to be changes to the platform count for the three industries. To calculate the amount, we will multiply the amount with the growth coefficients."""

#Filtering the df based on only the 3 industries
df_education = df_payouts_industries_merged_2[df_payouts_industries_merged_2.industry == 'Education']
df_food_beverage = df_payouts_industries_merged_2[df_payouts_industries_merged_2.industry == 'Food & Beverage']
df_hotel = df_payouts_industries_merged_2[df_payouts_industries_merged_2.industry == 'hotels, restaurants & leisure']
#multiply payout by expected growth in the number of platforms by industry
df_hotel['amount_exp(1000$)'] = df_hotel['amount(1000$)']*(5/13)
df_hotel['amount_exp(1000$/day)'] = df_hotel['amount_exp(1000$)']/52
df_food_beverage['amount_exp(1000$)'] = df_food_beverage['amount(1000$)']*(40/15)
df_food_beverage['amount_exp(1000$/day)'] = df_food_beverage['amount_exp(1000$)']/52
df_education['amount_exp(1000$)'] = df_education['amount(1000$)']*(15/5)
df_education['amount_exp(1000$/day)'] = df_education['amount_exp(1000$)']/52

df_hotel

#total payout
df_total_payout = df_payouts_industries_merged_2
df_total_payout = df_total_payout.drop(['weekday','amount'], axis = 1).groupby(['industry'], as_index=False).sum()
df_total_payout

#multiply payout by expected growth in the number of platforms by industry
df_total_payout_education = df_total_payout[df_total_payout.industry == 'Education']
df_total_payout_education['amount(1000$/day)'] = df_total_payout_education['amount(1000$)']/365
df_total_payout_education['amount_exp(1000$)'] = df_total_payout_education['amount(1000$)']*(15/5)
df_total_payout_education['amount_exp(1000$/day)'] = df_total_payout_education['amount_exp(1000$)']/365

df_total_payout_hotel = df_total_payout[df_total_payout.industry == 'hotels, restaurants & leisure']
df_total_payout_hotel['amount(1000$/day)'] = df_total_payout_hotel['amount(1000$)']/365
df_total_payout_hotel['amount_exp(1000$)'] = df_total_payout_hotel['amount(1000$)']*(5/13)
df_total_payout_hotel['amount_exp(1000$/day)'] = df_total_payout_hotel['amount_exp(1000$)']/365

df_total_payout_food = df_total_payout[df_total_payout.industry == 'Food & Beverage']
df_total_payout_food['amount(1000$/day)'] = df_total_payout_food['amount(1000$)']/365
df_total_payout_food['amount_exp(1000$)'] = df_total_payout_food['amount(1000$)']*(40/15)
df_total_payout_food['amount_exp(1000$/day)'] = df_total_payout_food['amount_exp(1000$)']/365

df_total_payout_food

df_total_payout_education

df_total_payout_hotel

# Combining all industry data
df_combined = pd.concat([df_total_payout_food, df_total_payout_education, df_total_payout_hotel])


# Calculate percentage change
df_combined['percentage_change'] = ((df_combined['amount_exp(1000$/day)'] - df_combined['amount(1000$/day)']) / df_combined['amount(1000$/day)']) * 100

# Bar width
width = 0.35

# Position of bars on x-axis
x = range(len(df_combined['industry']))

# Plotting the bar graph
plt.figure(figsize=(10, 8))


# Bar for 2018 data
bars1 = plt.bar(x, df_combined['amount(1000$/day)'], width, label='Amount(1000$/day) 2018', color='skyblue')
bars2 = plt.bar([p + width for p in x], df_combined['amount_exp(1000$/day)'], width, label='Amount Expected(1000$/day) 2019', color='salmon')

# Add value labels for each bar
for bar in bars1:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 10, f'{yval:.2f}', ha='center', va='bottom')

for bar in bars2:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 10, f'{yval:.2f}', ha='center', va='bottom')



# Add percentage change labels next to each bar
for i, bar in enumerate(bars1):
    change = df_combined.iloc[i]['percentage_change']
    label = f'{change:.2f}%'
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50, label, ha='center', va='bottom', color='red' if change < 0 else 'green')


# Labeling the axes and title
plt.xlabel('Industry')
plt.ylabel('Amount')
plt.title('Comparison of Amount and Amount Expected for Different Industries (2018 vs 2019)')
plt.xticks([p + 1.5 * width for p in x], df_combined['industry'])
plt.legend()

# Adjusting the y-axis limits
plt.ylim(0, max(df_combined['amount_exp(1000$/day)']) + 200)

plt.tight_layout()
plt.show()